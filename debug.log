Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
"POST /record HTTP/1.1" 500 181360
2021-05-14 12:51:51 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 12:51:52 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 12:51:52 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 12:51:52 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 12:52:00 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 12:52:00 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 12:52:02 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 12:52:02 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 12:53:08 [INFO    ] (modeling.from_pretrained) loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/akshay/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2021-05-14 12:53:08 [INFO    ] (modeling.from_pretrained) extracting archive file /home/akshay/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpdfdpzaao
2021-05-14 12:53:12 [INFO    ] (modeling.from_pretrained) Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-05-14 12:53:14 [INFO    ] (modeling.from_pretrained) Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-05-14 12:53:14 [INFO    ] (modeling.from_pretrained) Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-05-14 12:53:16 [INFO    ] (tokenization.from_pretrained) loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/akshay/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2021-05-14 12:53:16 [ERROR   ] (log.log_response) Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
2021-05-14 12:53:16 [ERROR   ] (log.log_response) Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
2021-05-14 12:53:16 [ERROR   ] (basehttp.log_message) "POST /record HTTP/1.1" 500 181787
2021-05-14 12:53:16 [ERROR   ] (basehttp.log_message) "POST /record HTTP/1.1" 500 181787
2021-05-14 14:18:08 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 14:18:10 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 14:18:10 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 14:18:10 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 14:18:12 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 14:18:12 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 14:18:12 [INFO    ] (basehttp.log_message) "GET /static/dist/css/style.css HTTP/1.1" 200 4096
2021-05-14 14:18:12 [INFO    ] (basehttp.log_message) "GET /static/dist/css/style.css HTTP/1.1" 200 4096
2021-05-14 14:18:12 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 14:18:12 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 14:18:12 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 14:18:12 [WARNING ] (basehttp.log_message) "GET /favicon.ico HTTP/1.1" 404 2490
2021-05-14 14:18:12 [WARNING ] (basehttp.log_message) "GET /favicon.ico HTTP/1.1" 404 2490
2021-05-14 14:18:15 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 14:18:15 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 14:19:24 [INFO    ] (modeling.from_pretrained) loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/akshay/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2021-05-14 14:19:24 [INFO    ] (modeling.from_pretrained) extracting archive file /home/akshay/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp9ts3ohcx
2021-05-14 14:19:27 [INFO    ] (modeling.from_pretrained) Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2021-05-14 14:19:29 [INFO    ] (modeling.from_pretrained) Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-05-14 14:19:29 [INFO    ] (modeling.from_pretrained) Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2021-05-14 14:19:31 [INFO    ] (tokenization.from_pretrained) loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/akshay/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2021-05-14 14:19:31 [ERROR   ] (log.log_response) Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
2021-05-14 14:19:31 [ERROR   ] (log.log_response) Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
2021-05-14 14:19:31 [ERROR   ] (log.log_response) Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
2021-05-14 14:19:31 [ERROR   ] (basehttp.log_message) "POST /record HTTP/1.1" 500 182063
2021-05-14 14:19:31 [ERROR   ] (basehttp.log_message) "POST /record HTTP/1.1" 500 182063
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
Watching for file changes with StatReloader
Watching for file changes with StatReloader
"GET / HTTP/1.1" 200 8202
"GET / HTTP/1.1" 200 8202
"GET /static/dist/css/style.css HTTP/1.1" 200 4096
"GET /static/dist/css/style.css HTTP/1.1" 200 4096
"GET /record HTTP/1.1" 200 7589
"GET /record HTTP/1.1" 200 7589
loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/akshay/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
extracting archive file /home/akshay/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgfu0fyad
Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/akshay/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
Internal Server Error: /record
Traceback (most recent call last):
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/exception.py", line 47, in inner
    response = get_response(request)
  File "/home/akshay/.local/lib/python3.6/site-packages/django/core/handlers/base.py", line 181, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/views.py", line 21, in record
    res = analyze()
  File "/home/akshay/Desktop/IIITB/SPE_Speech_Evaluator/speech/Analyzer.py", line 135, in analyze
    attention_mask=prediction_masks.to(device).long())
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 989, in forward
    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 733, in forward
    output_all_encoded_layers=output_all_encoded_layers)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 406, in forward
    hidden_states = layer_module(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 391, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 349, in forward
    self_output = self.self(input_tensor, attention_mask)
  File "/home/akshay/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/akshay/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py", line 312, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (12) must match the size of tensor b (0) at non-singleton dimension 1
"POST /record HTTP/1.1" 500 182802
"POST /record HTTP/1.1" 500 182802
2021-05-14 19:01:03 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 19:01:05 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 19:01:05 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 19:01:05 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 19:01:06 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 19:01:06 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 19:01:22 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 19:01:22 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 19:01:22 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 19:01:22 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 19:01:22 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 19:01:22 [WARNING ] (basehttp.log_message) "GET /favicon.ico HTTP/1.1" 404 2490
2021-05-14 19:01:22 [WARNING ] (basehttp.log_message) "GET /favicon.ico HTTP/1.1" 404 2490
2021-05-14 19:04:00 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 19:04:02 [INFO    ] (modeling.<module>) Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-05-14 19:04:02 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 19:04:02 [INFO    ] (autoreload.run_with_reloader) Watching for file changes with StatReloader
2021-05-14 19:04:53 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 19:04:53 [INFO    ] (basehttp.log_message) "GET / HTTP/1.1" 200 8202
2021-05-14 19:04:53 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 19:04:53 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 19:04:53 [WARNING ] (log.log_response) Not Found: /favicon.ico
2021-05-14 19:04:53 [WARNING ] (basehttp.log_message) "GET /favicon.ico HTTP/1.1" 404 2490
2021-05-14 19:04:53 [WARNING ] (basehttp.log_message) "GET /favicon.ico HTTP/1.1" 404 2490
2021-05-14 19:04:55 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
2021-05-14 19:04:55 [INFO    ] (basehttp.log_message) "GET /record HTTP/1.1" 200 7589
